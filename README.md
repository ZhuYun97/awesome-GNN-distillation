# awesome-GNN-distillation
Papers of distilling Graph Neural Network
1. [CVPR2020] Distilling Knowledge from Graph Convolutional Networks \[[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Distilling_Knowledge_From_Graph_Convolutional_Networks_CVPR_2020_paper.pdf)\]\[code\]
2. [IJCAI2021] On Self-Distilling Graph Neural Network\[[paper](https://arxiv.org/abs/2011.02255)\]\[code\]
3. [WWW2021] Extract the Knowledge of Graph Neural Networks and Go Beyond it: An Effective Knowledge Distillation Framework\[[paper](https://arxiv.org/abs/2103.02885)\]\[[code](https://github.com/BUPT-GAMMA/CPF)\]
4. [Arxiv2104] GKD: Semi-supervised Graph Knowledge Distillation for Graph-Independent Inference \[[paper](https://arxiv.org/abs/2104.03597)\]\[code\]
5. [Arxiv2105] Graph-Free Knowledge Distillation for Graph Neural Networks \[[paper](https://arxiv.org/pdf/2105.07519.pdf)\]\[code]
6. [Arxiv2106] Distilling Self-Knowledge From Contrastive Links to Classify Graph Nodes Without Passing Messages \[[paper](https://arxiv.org/pdf/2106.08541.pdf)\]\[[]()\]
7. [KDD2021] ROD: Reception-aware Online Distillation for Sparse Graphs \[[paper](https://arxiv.org/abs/2107.11789)\]\[[code](https://github.com/zwt233/ROD)\]
8. [Arxiv2108] Transferring Knowledge Distillation for Multilingual Social Event Detection \[[paper](https://arxiv.org/abs/2108.03084)\]\[[code](https://github.com/RingBDStack/CLKD)\]
9. [Arxiv2108] Distilling Holistic Knowledge with Graph Neural Networks \[[paper](Distilling Holistic Knowledge with Graph Neural Networks)\]\[code\]
10. [Arxiv2110] Scalable Consistency Training for Graph Neural Networks via Self-Ensemble Self-Distillation \[[paper](https://arxiv.org/abs/2110.06290)\]\[code\]
11. [Arxiv2110] Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation \[[paper](https://arxiv.org/pdf/2110.08727.pdf)\]\[code\]
12. [Arxiv2111] Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods \[[paper](https://arxiv.org/pdf/2111.04840.pdf)\]\[[code](https://github.com/amazon-research/gnn-tail-generalization)\]
13. [Arxiv2111] On Representation Knowledge Distillation for Graph Neural Networks \[[paper](https://arxiv.org/pdf/2111.04964.pdf)\]\[code\]
